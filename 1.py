from langchain.llms import Ollama


llm = Ollama(model="orca-mini", temperature=0)







#### TODO:

1. create github
2. push repo
3. pull from fgpt
4. open 888 sec-group
5. run remote notebook
6. access remotely fgpt:8888
7. run notebook with local ollama
